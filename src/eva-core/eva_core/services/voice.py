"""
Voice Service â€” Interface vocale (STT / TTS) pour EVA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FonctionnalitÃ©s :
- Transcription audio â†’ texte (Speech-to-Text via SpeechRecognition / Whisper)
- SynthÃ¨se texte â†’ audio (Text-to-Speech stub, extensible vers Coqui/Piper)

Les imports sont conditionnels pour permettre le fonctionnement sans les deps lourdes.
"""

import asyncio
import io
import logging
from typing import Optional

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTS CONDITIONNELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

try:
    import speech_recognition as sr
    SPEECH_RECOGNITION_AVAILABLE = True
except ImportError:
    SPEECH_RECOGNITION_AVAILABLE = False
    sr = None


class VoiceService:
    """
    Service d'interface vocale pour EVA.

    Si SpeechRecognition est installÃ©, la transcription fonctionne.
    Sinon, le service retourne des messages d'erreur gracieux.
    """

    def __init__(self):
        if SPEECH_RECOGNITION_AVAILABLE:
            self.recognizer = sr.Recognizer()
            logger.info("âœ… Voice Service initialisÃ© (SpeechRecognition disponible)")
        else:
            self.recognizer = None
            logger.warning(
                "âš ï¸ SpeechRecognition non installÃ©. "
                "Le service vocal est en mode dÃ©gradÃ©."
            )

    @property
    def is_available(self) -> bool:
        return self.recognizer is not None

    async def transcribe(self, audio_data: bytes) -> str:
        """
        Transcrit un flux audio en texte.

        Args:
            audio_data: Bytes bruts du fichier audio (WAV, FLAC, etc.)

        Returns:
            Le texte transcrit, ou un message d'erreur.
        """
        if not self.is_available:
            return "[Service vocal dÃ©sactivÃ© â€” SpeechRecognition non installÃ©]"

        try:
            # ExÃ©cuter la transcription dans un thread sÃ©parÃ© (CPU-bound)
            text = await asyncio.to_thread(self._transcribe_sync, audio_data)
            logger.info(f"ðŸŽ¤ Transcription: '{text[:80]}...'")
            return text
        except Exception as e:
            logger.error(f"Erreur transcription: {e}")
            return f"[Erreur de transcription: {e}]"

    def _transcribe_sync(self, audio_data: bytes) -> str:
        """Transcription synchrone (exÃ©cutÃ©e dans un thread)."""
        audio_file = io.BytesIO(audio_data)
        with sr.AudioFile(audio_file) as source:
            audio = self.recognizer.record(source)

        try:
            # Utiliser Google Speech Recognition (gratuit, limitÃ©)
            text = self.recognizer.recognize_google(audio, language="fr-FR")
            return text
        except sr.UnknownValueError:
            return "[Audio incomprÃ©hensible]"
        except sr.RequestError as e:
            return f"[Erreur service de reconnaissance: {e}]"

    async def synthesize_speech(self, text: str) -> bytes:
        """
        SynthÃ©tise du texte en audio (TTS).

        Stub actuel â€” en production, connecter Ã  Coqui TTS, Piper, ou gTTS.

        Args:
            text: Le texte Ã  convertir en parole.

        Returns:
            Bytes audio (format WAV).
        """
        logger.info(f"ðŸ”Š TTS (stub): '{text[:60]}...'")
        # Placeholder â€” retourne un silence WAV minimal
        # En production : utiliser gTTS, Coqui TTS, ou Piper
        await asyncio.sleep(0.1)
        return b""  # Vide â€” le frontend dÃ©tecte et affiche le texte
