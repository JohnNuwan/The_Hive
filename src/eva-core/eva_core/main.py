"""
Application FastAPI Principale pour l'Orchestrateur EVA (Core).

Ce module est le point d'entr√©e de l'API REST centrale de THE HIVE.
Il g√®re :
- L'orchestration des messages utilisateurs.
- Le routage des intentions (Intents) vers les Experts appropri√©s via Redis.
- La gestion de la m√©moire √† court et long terme (RAG).
- Le cycle de vie de l'application (connexions BDD, Redis).

Architecture :
    - FastAPI pour le serveur web asynchrone.
    - Redis pour la communication inter-agents (Pub/Sub).
    - TimescaleDB/Qdrant pour le stockage.
"""

import logging
from contextlib import asynccontextmanager
from datetime import datetime
from typing import Any
from uuid import UUID, uuid4

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

from shared import (
    ChatMessage,
    Intent,
    MessageRole,
    Settings,
    get_settings,
)
from shared.redis_client import get_redis_client, init_redis

from eva_core.router.intent import IntentRouter
from eva_core.services.llm import LLMService, get_llm_service
from eva_core.services.memory import MemoryService, get_memory_service

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MOD√àLES API
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class ChatRequest(BaseModel):
    """Requ√™te de chat"""
    message: str = Field(..., min_length=1, max_length=4000)
    session_id: UUID | None = None


class ChatResponse(BaseModel):
    """R√©ponse de chat"""
    message: str
    session_id: UUID
    intent: Intent | None = None
    metadata: dict[str, Any] = {}
    timestamp: datetime = Field(default_factory=datetime.now)


class HealthResponse(BaseModel):
    """R√©ponse de sant√©"""
    status: str = "ok"
    version: str = "0.1.0"
    environment: str
    timestamp: datetime = Field(default_factory=datetime.now)


class SessionResponse(BaseModel):
    """R√©ponse cr√©ation session"""
    session_id: UUID
    created_at: datetime = Field(default_factory=datetime.now)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# LIFECYCLE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    G√®re le cycle de vie de l'application (D√©marrage et Arr√™t).

    Cette fonction est ex√©cut√©e au lancement et √† l'arr√™t du serveur FastAPI.
    Elle est responsable de :
    1. Charger la configuration et les secrets.
    2. Initialiser les connexions aux bases de donn√©es (Redis, Postgres, Qdrant).
    3. Instancier les services singletons (LLM, Router, Memory).
    4. Nettoyer les ressources proprement lors de l'arr√™t (Graceful Shutdown).

    Args:
        app (FastAPI): L'instance de l'application en cours.

    Yields:
        None: Rend la main √† l'application une fois l'initialisation termin√©e.
    """
    # Startup
    logger.info("üöÄ D√©marrage EVA Core...")
    settings = get_settings()
    logger.info(f"Environnement: {settings.environment}")

    # Initialiser Redis
    try:
        await init_redis()
        logger.info("‚úÖ Redis connect√©")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Redis non disponible: {e}")

    # Initialiser les services
    app.state.settings = settings
    app.state.intent_router = IntentRouter()
    app.state.llm_service = get_llm_service()
    app.state.memory_service = get_memory_service()
    
    # Int√©gration Biblio_IA / PromptMaster
    from eva_core.services.prompt_master import PromptMaster
    app.state.prompt_master = PromptMaster()

    # Int√©gration MQTT
    from shared.mqtt_client import EVAMQTTClient
    app.state.mqtt = EVAMQTTClient("core")
    await app.state.mqtt.connect()

    logger.info("‚úÖ EVA Core pr√™t avec moteur de prompts Biblio_IA et lien MQTT")

    # D√©marrage de l'orchestrateur de survie
    import asyncio
    asyncio.create_task(self_healing_orchestrator())

    yield

    # Shutdown
    logger.info("üõë Arr√™t EVA Core...")
    redis_client = get_redis_client()
    await redis_client.disconnect()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# APPLICATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


app = FastAPI(
    title="EVA Core API",
    description="API principale de l'Orchestrateur EVA - THE HIVE",
    version="0.1.0",
    lifespan=lifespan,
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # √Ä restreindre en production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ENDPOINTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@app.get("/health", response_model=HealthResponse, tags=["Syst√®me"])
async def health_check() -> HealthResponse:
    """
    V√©rifie l'√©tat de sant√© op√©rationnel de l'API (Health Check).

    Utilis√© par Docker, K8s ou le Watchdog (ESP32) pour v√©rifier si le service
    est en vie et r√©actif. Ne v√©rifie pas n√©cessairement toutes les d√©pendances
    profondes pour √©viter les temps de latence, mais confirme que le thread
    principal tourne.

    Returns:
        HealthResponse: Objet contenant le statut 'ok', la version et l'environnement.
    """
    settings: Settings = app.state.settings
    return HealthResponse(
        status="ok",
        environment=settings.environment,
    )


@app.post("/session", response_model=SessionResponse, tags=["Chat"])
async def create_session() -> SessionResponse:
    """
    Initialise une nouvelle session de conversation.

    G√©n√®re un identifiant unique (UUID) pour tracer le contexte d'une discussion
    entre l'utilisateur et EVA. Cet ID doit √™tre fourni dans les requ√™tes /chat
    suivantes pour maintenir l'historique-m√©moire.

    Returns:
        SessionResponse: Contient le nouvel UUID de session g√©n√©r√©.
    """
    session_id = uuid4()
    logger.info(f"Nouvelle session cr√©√©e: {session_id}")
    return SessionResponse(session_id=session_id)


@app.post("/chat", response_model=ChatResponse, tags=["Chat"])
async def chat(request: ChatRequest) -> ChatResponse:
    """
    Traite un message utilisateur et g√©n√®re une r√©ponse orchestr√©e.

    C'est le c≈ìur r√©actif du syst√®me. Le flux de traitement est le suivant :
    1. **R√©ception** : Validation du payload et r√©cup√©ration de la session.
    2. **Classification** : Le Router analyse l'intention (Intent) du message.
    3. **Routage** :
        - Si l'intent concerne le CORE (Chat g√©n√©ral), le LLM r√©pond directement.
        - Si l'intent est sp√©cialis√© (ex: Trading), le message est publi√© sur Redis
          pour l'Expert concern√© (ex: Banker).
    4. **M√©morisation** : Le message utilisateur est archiv√© dans la m√©moire vectorielle.

    Args:
        request (ChatRequest): Le message de l'utilisateur et l'ID de session.

    Returns:
        ChatResponse: La r√©ponse textuelle (ou confirmation de dispatch) et les m√©tadonn√©es.

    Raises:
        HTTPException(500): En cas d'erreur critique de traitement ou de connexion Redis.
    """
    session_id = request.session_id or uuid4()
    
    try:
        # Cr√©er le message utilisateur
        user_message = ChatMessage(
            session_id=session_id,
            role=MessageRole.USER,
            content=request.message,
        )

        # Classification de l'intent
        intent_router: IntentRouter = app.state.intent_router
        intent = await intent_router.classify(request.message)
        logger.info(f"Intent classifi√©: {intent.intent_type} (confiance: {intent.confidence:.2f})")

        # G√©n√©rer la r√©ponse selon l'intent
        llm_service: LLMService = app.state.llm_service
        
        if intent.target_expert == "core":
            # Le Core r√©pond directement
            prompt_master: PromptMaster = app.state.prompt_master
            method = "react" if intent.confidence < 0.8 else "costar"
            wrapped_message = prompt_master.wrap_with_method(request.message, method=method)
            expert_injector = prompt_master.get_expert_injector("core")
            
            response_text = await llm_service.generate_response(
                messages=[ChatMessage(
                    session_id=session_id,
                    role=MessageRole.USER,
                    content=wrapped_message
                )],
                system_prompt=f"{expert_injector}\nTu es EVA, une IA assistante personnelle intelligente.",
            )
        elif intent.target_expert == "all":
            # SWARM MODE: Parall√©lisation sur tous les agents concern√©s
            redis_client = get_redis_client()
            await redis_client.broadcast_to_swarm(
                source="core",
                action=intent.intent_type.value,
                payload={
                    "session_id": str(session_id),
                    "message": request.message,
                    "entities": intent.entities,
                    "mode": "parallel"
                },
            )
            response_text = "Activation du Swarm Mode. Tous les experts concern√©s travaillent en parall√®le..."
        else:
            # Routage classique vers un expert unique
            redis_client = get_redis_client()
            payload = {
                "session_id": str(session_id),
                "message": request.message,
                "entities": intent.entities,
            }
            await redis_client.send_to_agent(
                source="core",
                target=intent.target_expert,
                action=intent.intent_type.value,
                payload=payload,
            )
            
            # Si l'expert est le Banker, on double l'envoi sur MQTT pour la fiabilit√© (Critical Path)
            if intent.target_expert == "banker" and intent.intent_type.value in ["TRADE", "ORDER"]:
                mqtt_client: EVAMQTTClient = app.state.mqtt
                await mqtt_client.publish("eva/banker/requests/critical", payload, qos=2)
                logger.info("üõ°Ô∏è Critical Order mirrored on MQTT (QoS 2)")

            response_text = f"Consultation de l'expert {intent.target_expert} lanc√©e."

        # Sauvegarder en m√©moire
        memory_service: MemoryService = app.state.memory_service
        await memory_service.store_message(user_message)

        return ChatResponse(
            message=response_text,
            session_id=session_id,
            intent=intent,
            metadata={
                "expert": intent.target_expert,
                "confidence": intent.confidence,
            },
        )

    except Exception as e:
        logger.exception(f"Erreur chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/swarm/drones", tags=["Swarm"])
async def get_active_drones() -> list[dict]:
    """
    R√©cup√®re la liste des drones autonomes actifs dans la ruche.
    """
    redis_client = get_redis_client()
    keys = await redis_client._client.keys("swarm:drone:*")
    drones = []
    for key in keys:
        drone_data = await redis_client.cache_get(key)
        if drone_data:
            drones.append(drone_data)
    return drones


async def self_healing_orchestrator():
    """
    Surveille la sant√© des drones dans Redis.
    Red√©marre automatiquement les missions si un heartbeat est perdu.
    """
    from datetime import datetime
    redis_client = get_redis_client()
    
    while True:
        try:
            keys = await redis_client._client.keys("swarm:drone:*")
            for key in keys:
                drone = await redis_client.cache_get(key)
                if drone and drone.get("status") == "active":
                    last_callback = datetime.fromisoformat(drone["last_callback"])
                    delta = (datetime.now() - last_callback).total_seconds()
                    
                    if delta > 120: # Drone silencieux depuis 2 min
                        logger.warning(f"Self-Healing: Drone {drone['name']} ({drone['id']}) perdu. Red√©ploiement...")
                        await redis_client.broadcast_to_swarm(
                            source="core",
                            action="SWARM_SURVEILLANCE",
                            payload={"redeploy_drone": drone["name"]}
                        )
                        # On marque le drone en erreur pour √©viter les doublons
                        drone["status"] = "healed"
                        await redis_client.cache_set(key, drone, ttl_seconds=3600)
                        
        except Exception as e:
            logger.error(f"Error in self-healing orchestrator: {e}")
            
        await asyncio.sleep(60) # V√©rification chaque minute


@app.get("/memory/search", tags=["M√©moire"])
async def search_memory(
    query: str,
    session_id: UUID | None = None,
    limit: int = 5,
) -> list[dict]:
    """
    Effectue une recherche s√©mantique dans la m√©moire vectorielle (RAG).

    Permet de retrouver des fragments de conversations pass√©es ou des documents
    ing√©r√©s pertinents par rapport √† la requ√™te `query`. Utilise Qdrant en backend.

    Args:
        query (str): Le texte ou le concept √† rechercher.
        session_id (UUID | None, optional): Filtrer par session sp√©cifique. Defaults to None.
        limit (int, optional): Nombre maximum de r√©sultats √† retourner. Defaults to 5.

    Returns:
        list[dict]: Liste des documents trouv√©s avec leur score de similarit√©.
    """
    memory_service: MemoryService = app.state.memory_service
    results = await memory_service.search(
        query=query,
        session_id=session_id,
        limit=limit,
    )
    return results


@app.get("/agents/status", tags=["Agents"])
async def agents_status() -> dict[str, Any]:
    """
    R√©cup√®re l'√©tat de connexion de tous les Experts du Conseil.

    Interroge le registre (Redis ou Heartbeat) pour savoir quels services sont
    actuellement en ligne et pr√™ts √† recevoir des ordres.

    Returns:
        dict[str, Any]: Dictionnaire {nom_expert: {status: 'online'|'offline', ...}}
    """
    # TODO: Impl√©menter la d√©couverte des agents via Redis
    return {
        "core": {"status": "online", "version": "0.1.0"},
        "banker": {"status": "unknown"},
        "sentinel": {"status": "unknown"},
    }
